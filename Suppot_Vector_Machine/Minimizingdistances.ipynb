{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimizing the Error\n",
    "- We want the boundary to be as far away from the points as possible.\n",
    "- Minimizing this error is what's going to give us the algorithm for Support Vector Machines.\n",
    "<br><br>\n",
    "<img src=\"imgs/minimizingtheError.png\"  width=\"750\" hieght=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/Error Function.png\"  width=\"750\" hieght=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification Error\n",
    "Now we don't just want a single line, we want the line with two extra lines that create the margin. And the equations for these lines are going to be\n",
    "- \\( Wx + b = 1 \\)\n",
    "- \\( Wx + b = -1 \\)\n",
    "<hr>\n",
    "let's split the error in two. In order to punish the points that are within the margin\n",
    "\n",
    "- The blue error will now start from the bottom line\n",
    "- The red error is going to now start from the top line\n",
    "<br><br>\n",
    "<img src=\"imgs/classification Error.png\" width=\"750\" hieght=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Margin Error\n",
    "<img src=\"imgs/Margin Error.png\" width=\"750\" hieght=\"400\">\n",
    "<hr>\n",
    "<img src=\"imgs/margin error2.png\" width=\"750\" hieght=\"400\">\n",
    " \n",
    "$$\n",
    "margin = 2 /  |W|\n",
    "$$\n",
    "$$\n",
    "error = ∣W∣ ^2\n",
    "$$\n",
    "\n",
    "for more info watch this <a href=\"https://learn.udacity.com/nanodegrees/nd230-palestine/parts/cd0025/lessons/ls13888/concepts/19e96cd0-6524-4849-be4f-6b2b7805c253?_gl=1*wa8o6t*_gcl_au*Njk0MDUwODcxLjE3MjM3Mzc5MTg.*_ga*MjE0NTk5NDUzLjE3MjM3Mzc5MTk.*_ga_CF22GKVCFK*MTczMDgwMTY2Ny40OC4xLjE3MzA4MDM0OTAuNjAuMC4w&lesson_tab=lesson\">Margin Error</a>\n",
    "\n",
    "and now we will use **gradient descent** to minmize this function if you wanna learn more aobut check \n",
    "<a herf=\"https://www.youtube.com/watch?v=HeFOUvFKNJ0\">this</a>\n",
    "<a herf=\"https://www.youtube.com/watch?v=fXQXE96r4AY\">this</a>\n",
    "<a herf=\"https://www.youtube.com/watch?v=vi7VhPzF7YY\">this</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C Parameter\n",
    "\n",
    "<img src=\"imgs/C Parameter1.png\" width=\"400px\">\n",
    "\n",
    "The **C parameter** - also referred to as the **C hyper-parameter** - determines how **flexible** we are willing to be with the points that fall on the wrong side of our dividing boundary.<br> The value of C ranges between 0 and infinity.<br>**When C is large, you are forcing your boundary to have fewer errors than when it is a small value**\n",
    "<hr><br>\n",
    "<img src=\"imgs/C parameter2.png\" width=\"550px\">\n",
    "\n",
    "- If we have a very large C, then the error is mostly the classification error, so we're focusing more on correctly classifying our points than on finding a good margin.\n",
    "- If the C is very small, then the error is mostly a margin error, so we're focusing mostly on a large margin than on classifying the points correctly.\n",
    "- It is used to modify the classification error.\n",
    "- It is a hyperparameter that provides some flexibility during training.\n",
    "- A large value for C will usually result in a small margin.\n",
    "- A small value for C will usually result in a large margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Kernel\n",
    "we use this kernel trick When the points **cannot be divided by a straight line**\n",
    "like this example \n",
    "<img src=\"imgs/Polynomial Kernel0.png\" width=\"640px\">\n",
    "<br>\n",
    "notic that we can't split the data with one straight line \n",
    "<img src=\"imgs/Polynomial Kernel.png\" width=\"640px\">\n",
    "<br> <br>\n",
    "and here you can see they split our data very well\n",
    "<hr>\n",
    "<img src=\"imgs/Polynomial Kernel2.png\" width=\"640px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alright let's look to higer dimensional example\n",
    "<img src=\"imgs/Polynomial Kernel4.png\">\n",
    "\n",
    "we can think of to methods here\n",
    "\n",
    "**first way** we can spreate them using a circal \n",
    "<br><hr>\n",
    "<img src=\"imgs/kernelt Trick circle method.png\">\n",
    "\n",
    "**second way** we can thing of higer dimenional \n",
    "<br><hr>\n",
    "<img src=\"imgs/kernelt Trick building method.png\">\n",
    "\n",
    "if you think about it you will notic that both are the same \n",
    "\n",
    "<img src=\"imgs/kernel Trick building vs circle method.png\">\n",
    "\n",
    "we mean by kernal a set of function that help us\n",
    "<br>\n",
    "if you wanna learn more about this see <a herf=\"https://learn.udacity.com/nanodegrees/nd230-palestine/parts/cd0025/lessons/ls13888/concepts/4d93cada-661d-4c86-9abb-5e2258b15b68?_gl=1*wa8o6t*_gcl_au*Njk0MDUwODcxLjE3MjM3Mzc5MTg.*_ga*MjE0NTk5NDUzLjE3MjM3Mzc5MTk.*_ga_CF22GKVCFK*MTczMDgwMTY2Ny40OC4xLjE3MzA4MDM0OTAuNjAuMC4w&lesson_tab=lesson\">this</a>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
